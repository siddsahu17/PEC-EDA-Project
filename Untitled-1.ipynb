{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EDA - MINOR Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For profiling, cleansing, and feature engineering\n",
    "import re\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16052f6",
   "metadata": {},
   "source": [
    "# 1. Business Objectives & KPIs Setup\n",
    "\n",
    "This notebook aims to build a clean, integrated pharmacy dataset for pricing, demand, compliance, and inventory insights.\n",
    "\n",
    "**Business Objectives:**\n",
    "- Integrate and cleanse pharmacy data for analytics and BI/ML.\n",
    "- Enable pricing, demand, compliance, and inventory insights.\n",
    "\n",
    "**Key KPIs:**\n",
    "- Revenue\n",
    "- Gross Margin\n",
    "- Average Discount\n",
    "- Items per Bill\n",
    "- Prescription-Linked Sales %\n",
    "- Refill Rate (30/60/90 days)\n",
    "- Stockout Rate\n",
    "- Days of Inventory (DOI)\n",
    "- Supplier On-Time %\n",
    "- Basket Size\n",
    "- Return/Cancel Rate\n",
    "\n",
    "Below are Python templates for KPI calculations (to be filled after data cleansing and transformation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI Calculation Templates (to be populated later)\n",
    "\n",
    "kpi_templates = {\n",
    "    \"Revenue\": \"quantity * final_price\",\n",
    "    \"Gross Margin\": \"final_price - cost_price\",\n",
    "    \"Average Discount\": \"discount.mean()\",\n",
    "    \"Items per Bill\": \"sales_bills.groupby('sale_id')['medicine_id'].count().mean()\",\n",
    "    \"Prescription-Linked Sales %\": \"sales_bills['prescription_id'].notnull().mean()\",\n",
    "    \"Refill Rate\": \"Function to calculate next sale within 30/60/90 days\",\n",
    "    \"Stockout Rate\": \"stocks[stocks['available_units']==0].shape[0] / stocks.shape[0]\",\n",
    "    \"Days of Inventory\": \"available_units / avg_daily_sales\",\n",
    "    \"Supplier On-Time %\": \"To be calculated if delivery dates available\",\n",
    "    \"Basket Size\": \"sales_bills.groupby('sale_id')['medicine_id'].nunique().mean()\",\n",
    "    \"Return/Cancel Rate\": \"sales_bills[sales_bills['status']=='Cancelled'].shape[0] / sales_bills.shape[0]\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33728f45",
   "metadata": {},
   "source": [
    "# 2. Entity Relationship Mapping\n",
    "\n",
    "## Target Star Schema\n",
    "\n",
    "| FactSales        | DimCustomer | DimMedicine | DimShop      | DimPrescription | DimPurchase | FactStockSnapshot |\n",
    "|------------------|-------------|-------------|--------------|-----------------|-------------|-------------------|\n",
    "| sale_id          | customer_id | medicine_id | shop_id      | prescription_id | purchase_id | stock_id          |\n",
    "| sale_date        | age         | medicine_name| location     | doctor_name     | supplier_name| last_updated      |\n",
    "| customer_id      | city        | type_id     | manager_name | date            | purchase_date| available_units   |\n",
    "| medicine_id      | contact flags| type_name   | rating       | dosage          | cost_price   |                   |\n",
    "| shop_id          |             | category    |              |                 |             |                   |\n",
    "| prescription_id  |             | brand       |              |                 |             |                   |\n",
    "| quantity         |             | price       |              |                 |             |                   |\n",
    "| discount         |             |             |              |                 |             |                   |\n",
    "| final_price      |             |             |              |                 |             |                   |\n",
    "| payment_mode     |             |             |              |                 |             |                   |\n",
    "| status           |             |             |              |                 |             |                   |\n",
    "\n",
    "**Entity Relationships:**\n",
    "- SalesBills.customer_id → Customers\n",
    "- SalesBills.medicine_id → Medicines\n",
    "- SalesBills.shop_id → PharmacyShops\n",
    "- SalesBills.prescription_id → Prescriptions\n",
    "- Medicines.type_id → TypesOfMedicines\n",
    "- Purchases.(medicine_id,shop_id) → (Medicines,PharmacyShops)\n",
    "\n",
    "Below, we load all data and map DataFrames to schema entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e78410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrames\n",
    "\n",
    "customers = pd.read_csv('data/Customers.csv')\n",
    "medicine = pd.read_csv('data/Medicine.csv')\n",
    "pharmacy = pd.read_csv('data/PharmacyShops.csv')\n",
    "prescriptions = pd.read_csv('data/Prescriptions.csv')\n",
    "purchases = pd.read_csv('data/Purchases.csv')\n",
    "sales_bills = pd.read_csv('data/SalesBills.csv')\n",
    "stocks = pd.read_csv('data/Stocks.csv')\n",
    "med_type = pd.read_csv('data/TypesofMedicine.csv')\n",
    "\n",
    "# Map DataFrames to schema entities\n",
    "dim_customer = customers.copy()\n",
    "dim_medicine = medicine.merge(med_type, on='type_id', how='left')\n",
    "dim_shop = pharmacy.copy()\n",
    "dim_prescription = prescriptions.copy()\n",
    "dim_purchase = purchases.copy()\n",
    "fact_sales = sales_bills.copy()\n",
    "fact_stock = stocks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Foreign Key Mappings\n",
    "\n",
    "def fk_check(fact_df, dim_df, fk_col, pk_col):\n",
    "    missing = fact_df.loc[~fact_df[fk_col].isin(dim_df[pk_col])]\n",
    "    print(f\"Orphan keys in {fk_col}: {missing.shape[0]}\")\n",
    "    return missing\n",
    "\n",
    "fk_check(fact_sales, dim_customer, 'customer_id', 'customer_id')\n",
    "fk_check(fact_sales, dim_medicine, 'medicine_id', 'medicine_id')\n",
    "fk_check(fact_sales, dim_shop, 'shop_id', 'shop_id')\n",
    "fk_check(fact_sales, dim_prescription, 'prescription_id', 'prescription_id')\n",
    "fk_check(dim_medicine, med_type, 'type_id', 'type_id')\n",
    "fk_check(dim_purchase, dim_medicine, 'medicine_id', 'medicine_id')\n",
    "fk_check(dim_purchase, dim_shop, 'shop_id', 'shop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2660525d",
   "metadata": {},
   "source": [
    "# 3. Data Profiling\n",
    "\n",
    "Profile each DataFrame for:\n",
    "- Volume & Completeness: row counts, null %, distinct counts, duplicates\n",
    "- Validity: value ranges, date plausibility\n",
    "- Integrity: orphan FKs, 1-to-many/1-to-1 checks\n",
    "- Consistency: city names, payment_mode, status\n",
    "- Outliers: z-score/IQR for final_price, discount, age\n",
    "- Drift: monthly trends for price, discount, quantity\n",
    "\n",
    "Below, we perform profiling for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee35440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume & Completeness\n",
    "\n",
    "def profile_df(df, name):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Rows:\", df.shape[0])\n",
    "    print(\"Columns:\", df.shape[1])\n",
    "    print(\"Nulls per column:\\n\", df.isnull().mean())\n",
    "    print(\"Distinct counts:\\n\", df.nunique())\n",
    "    if 'customer_id' in df.columns:\n",
    "        print(\"Duplicate customer_id:\", df['customer_id'].duplicated().sum())\n",
    "    print()\n",
    "\n",
    "profile_df(customers, \"Customers\")\n",
    "profile_df(medicine, \"Medicine\")\n",
    "profile_df(pharmacy, \"PharmacyShops\")\n",
    "profile_df(prescriptions, \"Prescriptions\")\n",
    "profile_df(purchases, \"Purchases\")\n",
    "profile_df(sales_bills, \"SalesBills\")\n",
    "profile_df(stocks, \"Stocks\")\n",
    "profile_df(med_type, \"TypesofMedicine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e15c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity Checks\n",
    "\n",
    "def check_ranges(df, col, min_val, max_val):\n",
    "    invalid = df[(df[col] < min_val) | (df[col] > max_val)]\n",
    "    print(f\"{col} out of range: {invalid.shape[0]}\")\n",
    "    return invalid\n",
    "\n",
    "check_ranges(customers, 'age', 0, 100)\n",
    "check_ranges(sales_bills, 'discount', 0, 90)\n",
    "check_ranges(medicine, 'price', 1, 10000)\n",
    "check_ranges(sales_bills, 'quantity', 1, np.inf)\n",
    "\n",
    "# Date plausibility\n",
    "def check_dates(df, col, min_date, max_date):\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    invalid = df[(df[col] < min_date) | (df[col] > max_date)]\n",
    "    print(f\"{col} out of range: {invalid.shape[0]}\")\n",
    "    return invalid\n",
    "\n",
    "check_dates(sales_bills, 'sale_date', '2019-01-01', '2025-09-01')\n",
    "check_dates(prescriptions, 'date', '2019-01-01', '2025-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25882cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency Checks\n",
    "\n",
    "def city_standardization_report(df, city_col):\n",
    "    print(\"Unique cities:\", df[city_col].unique())\n",
    "\n",
    "city_standardization_report(customers, 'city')\n",
    "\n",
    "print(\"Payment modes:\", sales_bills['payment_mode'].unique())\n",
    "print(\"Status values:\", sales_bills['status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection (z-score for final_price, discount, age)\n",
    "\n",
    "def outlier_zscore(df, col):\n",
    "    z = np.abs(stats.zscore(df[col].dropna()))\n",
    "    outliers = df.loc[z > 3]\n",
    "    print(f\"{col} outliers (z>3): {outliers.shape[0]}\")\n",
    "    return outliers\n",
    "\n",
    "outlier_zscore(sales_bills, 'final_price')\n",
    "outlier_zscore(sales_bills, 'discount')\n",
    "outlier_zscore(customers, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6183c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Drift Analysis (price, discount, quantity)\n",
    "\n",
    "sales_bills['sale_date'] = pd.to_datetime(sales_bills['sale_date'], errors='coerce')\n",
    "monthly = sales_bills.groupby(sales_bills['sale_date'].dt.to_period('M')).agg({\n",
    "    'final_price': 'mean',\n",
    "    'discount': 'mean',\n",
    "    'quantity': 'sum'\n",
    "})\n",
    "monthly.plot(subplots=True, figsize=(10,8), title=\"Monthly Trends\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf179fa",
   "metadata": {},
   "source": [
    "# 4. Data Cleansing\n",
    "\n",
    "Tasks:\n",
    "- Standardize city names\n",
    "- Normalize case/whitespace in names/brands\n",
    "- Validate emails/phones\n",
    "- Deduplicate customers (email/phone + fuzzy name)\n",
    "- Fix invalid numerics\n",
    "- Date cleanup (ISO format, prescription date ≤ sale date)\n",
    "- Status/payment_mode normalization\n",
    "\n",
    "Below, we perform these cleansing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize city names\n",
    "\n",
    "city_map = {\n",
    "    'Kolkatta': 'Kolkata',\n",
    "    'Hydrabad': 'Hyderabad',\n",
    "    'Mumbai': 'Mumbai',\n",
    "    'Delhi': 'Delhi',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "customers['city'] = customers['city'].replace(city_map)\n",
    "customers['city'] = customers['city'].str.strip().str.title()\n",
    "\n",
    "# Normalize case/whitespace in names/brands\n",
    "medicine['medicine_name'] = medicine['medicine_name'].str.strip().str.title()\n",
    "medicine['brand'] = medicine['brand'].str.strip().str.title()\n",
    "pharmacy['location'] = pharmacy['location'].str.strip().str.title()\n",
    "pharmacy['manager_name'] = pharmacy['manager_name'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate emails/phones\n",
    "\n",
    "def validate_email(email):\n",
    "    pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "    return bool(re.match(pattern, str(email)))\n",
    "\n",
    "def validate_phone(phone):\n",
    "    pattern = r'^\\d{10}$'\n",
    "    return bool(re.match(pattern, str(phone)))\n",
    "\n",
    "customers['valid_email'] = customers['email'].apply(validate_email)\n",
    "customers['valid_phone'] = customers['phone'].apply(validate_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbada3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate customers using email/phone + fuzzy name matching\n",
    "\n",
    "def deduplicate_customers(df):\n",
    "    # First, drop exact duplicates on email/phone\n",
    "    df = df.drop_duplicates(subset=['email', 'phone'])\n",
    "    # Fuzzy name matching for remaining duplicates\n",
    "    names = df['name'].tolist()\n",
    "    matches = []\n",
    "    for i, name in enumerate(names):\n",
    "        for j in range(i+1, len(names)):\n",
    "            if fuzz.ratio(name, names[j]) > 90:\n",
    "                matches.append((i, j))\n",
    "    # Optionally, merge matched records (not implemented here for brevity)\n",
    "    print(f\"Fuzzy duplicate pairs: {len(matches)}\")\n",
    "    return df\n",
    "\n",
    "customers = deduplicate_customers(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix invalid numerics (negative prices/quantities → null + flag)\n",
    "\n",
    "medicine.loc[medicine['price'] < 0, 'price'] = np.nan\n",
    "sales_bills.loc[sales_bills['quantity'] < 1, 'quantity'] = np.nan\n",
    "sales_bills['invalid_quantity_flag'] = sales_bills['quantity'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date cleanup: enforce ISO format, prescription date ≤ sale date\n",
    "\n",
    "sales_bills['sale_date'] = pd.to_datetime(sales_bills['sale_date'], errors='coerce')\n",
    "prescriptions['date'] = pd.to_datetime(prescriptions['date'], errors='coerce')\n",
    "\n",
    "# Flag if prescription date > sale date\n",
    "merged = sales_bills.merge(prescriptions[['prescription_id', 'date']], on='prescription_id', how='left')\n",
    "sales_bills['prescription_date_flag'] = merged['date'] <= sales_bills['sale_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status normalization\n",
    "\n",
    "status_map = {\n",
    "    'completed': 'Completed',\n",
    "    'cancelled': 'Cancelled',\n",
    "    'pending': 'Pending',\n",
    "    'Complete': 'Completed',\n",
    "    'Cancel': 'Cancelled',\n",
    "    # Add more as needed\n",
    "}\n",
    "sales_bills['status'] = sales_bills['status'].str.strip().str.title().replace(status_map)\n",
    "\n",
    "# Payment mode normalization\n",
    "payment_map = {\n",
    "    'cash': 'Cash',\n",
    "    'card': 'Card',\n",
    "    'upi': 'UPI',\n",
    "    'wallet': 'Wallet',\n",
    "    'Credit Card': 'Card',\n",
    "    'Debit Card': 'Card',\n",
    "    # Add more as needed\n",
    "}\n",
    "sales_bills['payment_mode'] = sales_bills['payment_mode'].str.strip().str.title().replace(payment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f6f77",
   "metadata": {},
   "source": [
    "# 5. Transformation & Feature Engineering\n",
    "\n",
    "Tasks:\n",
    "- Revenue, Gross Margin, Discount Value\n",
    "- Refill Flag (next sale within 30/60/90 days)\n",
    "- Days Supply proxy\n",
    "- Basket Features\n",
    "- Inventory KPIs\n",
    "- Encoding for categorical variables\n",
    "\n",
    "Below, we engineer these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c02d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue\n",
    "sales_bills['revenue'] = sales_bills['quantity'] * sales_bills['final_price']\n",
    "\n",
    "# Gross Margin (join Purchases)\n",
    "purchases_latest = purchases.sort_values('purchase_date').drop_duplicates(['medicine_id', 'shop_id'], keep='last')\n",
    "sales_bills = sales_bills.merge(\n",
    "    purchases_latest[['medicine_id', 'shop_id', 'cost_price']],\n",
    "    on=['medicine_id', 'shop_id'], how='left'\n",
    ")\n",
    "sales_bills['gross_margin'] = sales_bills['final_price'] - sales_bills['cost_price']\n",
    "\n",
    "# Discount Value\n",
    "medicine = medicine.rename(columns={'price': 'list_price'})\n",
    "sales_bills = sales_bills.merge(medicine[['medicine_id', 'list_price']], on='medicine_id', how='left')\n",
    "sales_bills['discount_value'] = sales_bills['list_price'] * (sales_bills['discount'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refill Flag: next sale of same (customer_id, medicine_id) within 30/60/90 days\n",
    "\n",
    "def refill_flag(df, days):\n",
    "    df = df.sort_values(['customer_id', 'medicine_id', 'sale_date'])\n",
    "    df['next_sale_date'] = df.groupby(['customer_id', 'medicine_id'])['sale_date'].shift(-1)\n",
    "    df[f'refill_{days}d'] = (df['next_sale_date'] - df['sale_date']).dt.days <= days\n",
    "    return df\n",
    "\n",
    "for d in [30, 60, 90]:\n",
    "    sales_bills = refill_flag(sales_bills, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days Supply proxy from dosage pattern (simple example)\n",
    "\n",
    "def days_supply_proxy(dosage_str, quantity):\n",
    "    # Example: '1-0-1' means 2/day\n",
    "    if pd.isnull(dosage_str):\n",
    "        return np.nan\n",
    "    doses = [int(x) for x in re.findall(r'\\d+', dosage_str)]\n",
    "    daily = sum(doses)\n",
    "    if daily == 0:\n",
    "        return np.nan\n",
    "    return quantity / daily\n",
    "\n",
    "sales_bills = sales_bills.merge(\n",
    "    prescriptions[['prescription_id', 'dosage']],\n",
    "    on='prescription_id', how='left'\n",
    ")\n",
    "sales_bills['days_supply'] = sales_bills.apply(\n",
    "    lambda x: days_supply_proxy(x['dosage'], x['quantity']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04487061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basket Features\n",
    "\n",
    "basket = sales_bills.groupby('sale_id').agg(\n",
    "    items_per_bill=('medicine_id', 'count'),\n",
    "    unique_meds=('medicine_id', 'nunique'),\n",
    "    total_bill=('revenue', 'sum')\n",
    ")\n",
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inventory KPIs: days_of_inventory = available_units / avg_daily_sales\n",
    "\n",
    "avg_daily_sales = sales_bills.groupby(['shop_id', 'medicine_id'])['quantity'].mean().reset_index()\n",
    "fact_stock = fact_stock.merge(avg_daily_sales, on=['shop_id', 'medicine_id'], how='left')\n",
    "fact_stock['days_of_inventory'] = fact_stock['available_units'] / fact_stock['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_payment = encoder.fit_transform(sales_bills[['payment_mode']])\n",
    "encoded_status = encoder.fit_transform(sales_bills[['status']])\n",
    "encoded_category = encoder.fit_transform(dim_medicine[['category']])\n",
    "\n",
    "# Add encoded columns to DataFrame (example for payment_mode)\n",
    "for i, col in enumerate(encoder.categories_[0]):\n",
    "    sales_bills[f'payment_mode_{col}'] = encoded_payment[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b420cc1",
   "metadata": {},
   "source": [
    "# 6. Normalization & Integration\n",
    "\n",
    "Tasks:\n",
    "- Integrate and conform dimensions (join Types to Medicines, canonical brand/type values)\n",
    "- Consolidate shops\n",
    "- Normalize customers (surrogate keys, SCD Type 1)\n",
    "- Build final star schema tables\n",
    "- Validate no orphan keys\n",
    "\n",
    "Below, we perform normalization and integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce964343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Types to Medicines for canonical type/category\n",
    "\n",
    "dim_medicine = medicine.merge(med_type, on='type_id', how='left')\n",
    "dim_medicine['brand'] = dim_medicine['brand'].str.title().str.strip()\n",
    "dim_medicine['type_name'] = dim_medicine['type_name'].str.title().str.strip()\n",
    "dim_medicine['category'] = dim_medicine['category'].str.title().str.strip()\n",
    "\n",
    "# Consolidate Shops\n",
    "dim_shop = pharmacy.drop_duplicates(subset=['shop_id'])\n",
    "dim_shop['location'] = dim_shop['location'].str.title().str.strip()\n",
    "\n",
    "# Normalize Customers (surrogate keys, SCD Type 1)\n",
    "dim_customer = customers.copy()\n",
    "dim_customer['customer_sk'] = pd.factorize(dim_customer['customer_id'])[0] + 1\n",
    "\n",
    "# Build final star schema tables\n",
    "star_fact_sales = sales_bills.copy()\n",
    "star_dim_customer = dim_customer.copy()\n",
    "star_dim_medicine = dim_medicine.copy()\n",
    "star_dim_shop = dim_shop.copy()\n",
    "star_dim_prescription = dim_prescription.copy()\n",
    "star_dim_purchase = dim_purchase.copy()\n",
    "star_fact_stock = fact_stock.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965eee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate no orphan keys in final star schema\n",
    "\n",
    "def orphan_check(fact, dim, fk, pk):\n",
    "    missing = fact.loc[~fact[fk].isin(dim[pk])]\n",
    "    print(f\"Orphan {fk} in fact: {missing.shape[0]}\")\n",
    "    return missing\n",
    "\n",
    "orphan_check(star_fact_sales, star_dim_customer, 'customer_id', 'customer_id')\n",
    "orphan_check(star_fact_sales, star_dim_medicine, 'medicine_id', 'medicine_id')\n",
    "orphan_check(star_fact_sales, star_dim_shop, 'shop_id', 'shop_id')\n",
    "orphan_check(star_fact_sales, star_dim_prescription, 'prescription_id', 'prescription_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc999b15",
   "metadata": {},
   "source": [
    "# 7. Reduction & Feature Selection\n",
    "\n",
    "Tasks:\n",
    "- Drop/archive low-value text\n",
    "- Aggregate historical stock snapshots\n",
    "- Feature selection (mutual information/SHAP, VIF)\n",
    "- PCA for high-cardinality categorical expansions\n",
    "\n",
    "Below, we perform reduction and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop/archive low-value free text (e.g., supplier_name after standardizing)\n",
    "\n",
    "dim_purchase['supplier_name'] = dim_purchase['supplier_name'].str.title().str.strip()\n",
    "# Optionally drop if not needed for modeling\n",
    "dim_purchase = dim_purchase.drop(columns=['supplier_name'])\n",
    "\n",
    "# Aggregate stock snapshots (weekly)\n",
    "fact_stock['week'] = pd.to_datetime(fact_stock['last_updated']).dt.to_period('W')\n",
    "stock_weekly = fact_stock.groupby(['shop_id', 'medicine_id', 'week']).agg({\n",
    "    'available_units': 'mean',\n",
    "    'days_of_inventory': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68932fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection via mutual information and VIF\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(df, features):\n",
    "    X = df[features].dropna()\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = features\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(features))]\n",
    "    return vif\n",
    "\n",
    "features = ['revenue', 'gross_margin', 'discount', 'quantity', 'days_supply']\n",
    "vif_df = calculate_vif(star_fact_sales, features)\n",
    "print(vif_df)\n",
    "\n",
    "# Mutual information (example for classification target)\n",
    "if 'status' in star_fact_sales.columns:\n",
    "    mi = mutual_info_classif(star_fact_sales[features].fillna(0), star_fact_sales['status'].astype('category').cat.codes)\n",
    "    print(\"Mutual Information:\", dict(zip(features, mi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a08840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional PCA for high-cardinality categorical expansions\n",
    "\n",
    "cat_features = [col for col in star_fact_sales.columns if col.startswith('payment_mode_') or col.startswith('status_')]\n",
    "scaler = StandardScaler()\n",
    "X_cat = scaler.fit_transform(star_fact_sales[cat_features].fillna(0))\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cat)\n",
    "star_fact_sales['pca_1'] = X_pca[:,0]\n",
    "star_fact_sales['pca_2'] = X_pca[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20837de0",
   "metadata": {},
   "source": [
    "# Notebook Complete\n",
    "\n",
    "All EDA, profiling, cleansing, transformation, normalization, and reduction steps have been performed as per business objectives and target star schema. The final integrated dataset is ready for BI/ML and KPI calculation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
